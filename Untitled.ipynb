{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ee8f4b-2a8f-4904-b88d-6fdf7752f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a424248-cc56-455e-98cb-84808d08f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization Explained\n",
    "#Initialize text\n",
    "corpus = \"\"\"If you’re working on a small-scale project that doesn’t require complex NLP tasks, NLTK might be a good choice due to its flexibility and ease of use. You can easily customize and fine-tune NLTK to suit your needs, and its extensive documentation makes it easy to get started.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16a8f89-e123-4b4a-88fa-49533bb1fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize paragraph to sentences\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f350bbc8-a342-485c-909c-8808f809f6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If you’re working on a small-scale project that doesn’t require complex NLP tasks, NLTK might be a good choice due to its flexibility and ease of use.',\n",
       " 'You can easily customize and fine-tune NLTK to suit your needs, and its extensive documentation makes it easy to get started.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = sent_tokenize(corpus)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9801695-3beb-40c4-a5d5-b695968c3efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If', 'you', '’', 're', 'working', 'on', 'a', 'small-scale', 'project', 'that', 'doesn', '’', 't', 'require', 'complex', 'NLP', 'tasks', ',', 'NLTK', 'might', 'be', 'a', 'good', 'choice', 'due', 'to', 'its', 'flexibility', 'and', 'ease', 'of', 'use', '.']\n",
      "['You', 'can', 'easily', 'customize', 'and', 'fine-tune', 'NLTK', 'to', 'suit', 'your', 'needs', ',', 'and', 'its', 'extensive', 'documentation', 'makes', 'it', 'easy', 'to', 'get', 'started', '.']\n"
     ]
    }
   ],
   "source": [
    "#Tokenize sentence to words\n",
    "#wordpunct_tokenize function tokenizes not only words but also punctuation marks but now word_tokenize also provides that functionality \n",
    "for doc in docs:\n",
    "    print(word_tokenize(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09099f-ebf1-4286-b7bd-ebfd7edf8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the difference between word_tokenize and TreebankWordTokenizer class?\n",
    "\"\"\"word_tokenize tokenizes punctuation marks and period at the end of each line while TreebankWordTokenizer tokenizes only words and not \n",
    "punctuations and only tokenizes period at the end of text and not for each ans every line\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
